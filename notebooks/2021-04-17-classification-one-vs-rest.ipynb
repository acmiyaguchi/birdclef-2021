{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f2db68c",
   "metadata": {},
   "source": [
    "# Some classification benchmarks\n",
    "\n",
    "I have a feeling that this isn't going to do so great, because chirping motif can pretty much be in any position. This would work better if I could extract the similarity scores from a representative sample from each class. I do need the methology in the future, so this isn't entirely in vain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fdc2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "\n",
    "\n",
    "def cens_per_sec(sample_rate, target):\n",
    "    \"\"\"Ensure this value is a multiple of 2**6\"\"\"\n",
    "    return (sample_rate // (target * (2 ** 6))) * (2 ** 6)\n",
    "\n",
    "def chroma_cens(data, sample_rate=22050, cens_sr=10):\n",
    "    return librosa.feature.chroma_cens(\n",
    "        data, sample_rate, hop_length=cens_per_sec(sample_rate, cens_sr)\n",
    "    )\n",
    "\n",
    "def normalize(row):\n",
    "    if row.shape[0] == 600:\n",
    "        return row\n",
    "    if row.shape[0] > 600:\n",
    "        return row[:600]\n",
    "    if row.shape[0] < 600:\n",
    "        return np.append(row, np.zeros(600-row.shape[0]))\n",
    "\n",
    "    \n",
    "root = Path(\"../data\")\n",
    "motif = root / \"motif/train_short_audio\"\n",
    "\n",
    "data = []\n",
    "species = []\n",
    "audio = []\n",
    "for path in motif.glob(\"**/*.npy\"):\n",
    "    data.append(np.load(path))\n",
    "    species.append(path.parent.parent.name)\n",
    "    audio.append(path.as_posix().replace(\".npy\", \".ogg\"))\n",
    "\n",
    "# TODO: let's write out the cens data to file too, it's slow here\n",
    "chroma = [chroma_cens(row).reshape(-1) for row in data]\n",
    "X = np.stack([normalize(r) for r in chroma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77fa780e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592, 600)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce479d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(species)\n",
    "y = le.transform(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "623c6420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5546218487394958"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4a6be",
   "metadata": {},
   "source": [
    "Yeah, that's pretty awful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
